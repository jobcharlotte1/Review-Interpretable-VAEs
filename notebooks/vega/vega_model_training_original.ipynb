{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddef696-fb63-4128-a8f2-b4d35e394a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import vega\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('/home/user/Review-Interpretable-VAEs/Review-Interpretable-VAEs/cloned_github_models/vega/vega-reproducibility/src')\n",
    "import vanilla_vae\n",
    "import train_vanilla_vae_suppFig1\n",
    "import utils\n",
    "from utils import *\n",
    "from learning_utils import *\n",
    "from vanilla_vae import VanillaVAE\n",
    "from vega_model import VEGA\n",
    "\n",
    "import sys\n",
    "import os \n",
    "from pathlib import Path\n",
    "sys.path.append('/home/BS94_SUR/phD/review/utils/utils_evaluation')\n",
    "import utils_train_models\n",
    "from utils_train_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34edce5b-9d9a-4769-888d-25aaf3b1613e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled = True\n",
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', dev, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54361673-c6ce-4e02-a1d9-c5648b6e36b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '/home/BS94_SUR/phD/review/models reproductibility/pmvae/scripts/data/kang_count.h5ad'\n",
    "pathway_file = '/home/BS94_SUR/phD/review/models reproductibility/VEGA/vega-reproducibility/data/reactomes.gmt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b425c339-c1de-4aee-8165-3d328c0637aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_model_path = '/home/BS94_SUR/phD/review/notebooks/review VAEs/perturbation/vega/model inference/saved model/'\n",
    "path_to_save_embeddings = '/home/BS94_SUR/phD/review/notebooks/review VAEs/perturbation/vega/model inference/original/embeddings'\n",
    "path_to_save_reconstructed = '/home/BS94_SUR/phD/review/notebooks/review VAEs/perturbation/vega/model inference/original/reconstructed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26d9fd44-7510-4846-b594-7278432878ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_model = 'VEGA'\n",
    "name_dataset = 'kang'\n",
    "column_labels_name = 'condition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77fe6f2f-0378-4b01-a051-1ea6004075a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_training= 1\n",
    "train_size = 0.9\n",
    "select_hvg = False\n",
    "n_top_genes = 2000\n",
    "preprocess = False\n",
    "exist_val_set = True\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6b71e5a-6723-4de2-8343-f465b47f70e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "perturbation = 'original'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fedb624-7e5e-489a-9c9b-dea3e083643b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata = sc.read(data_path)\n",
    "pathway_dict = read_gmt(pathway_file, min_g=0, max_g=1000)\n",
    "pathway_mask = create_pathway_mask(adata.var.index.tolist(), pathway_dict, add_missing=1, fully_connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73738902-76d9-4d1c-b2d7-a54339d11dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[Epoch 1] | loss: 101.180 | test_loss: 73.564 |\n",
      "[Epoch 2] | loss: 77.625 | test_loss: 62.244 |\n",
      "[Epoch 3] | loss: 72.005 | test_loss: 59.464 |\n",
      "[Epoch 4] | loss: 70.172 | test_loss: 58.128 |\n",
      "[Epoch 5] | loss: 69.155 | test_loss: 57.103 |\n",
      "[Epoch 6] | loss: 68.455 | test_loss: 56.003 |\n",
      "[Epoch 7] | loss: 67.812 | test_loss: 55.280 |\n",
      "[Epoch 8] | loss: 67.393 | test_loss: 54.779 |\n",
      "[Epoch 9] | loss: 67.031 | test_loss: 54.342 |\n",
      "[Epoch 10] | loss: 66.689 | test_loss: 53.918 |\n",
      "[Epoch 11] | loss: 66.437 | test_loss: 53.740 |\n",
      "[Epoch 12] | loss: 66.330 | test_loss: 53.208 |\n",
      "[Epoch 13] | loss: 66.062 | test_loss: 52.781 |\n",
      "[Epoch 14] | loss: 65.764 | test_loss: 52.904 |\n",
      "[Epoch 15] | loss: 65.611 | test_loss: 52.564 |\n",
      "[Epoch 16] | loss: 65.620 | test_loss: 52.126 |\n",
      "[Epoch 17] | loss: 65.288 | test_loss: 51.982 |\n",
      "[Epoch 18] | loss: 65.273 | test_loss: 51.720 |\n",
      "[Epoch 19] | loss: 65.126 | test_loss: 51.531 |\n",
      "[Epoch 20] | loss: 64.958 | test_loss: 51.636 |\n",
      "[Epoch 21] | loss: 65.031 | test_loss: 51.233 |\n",
      "[Epoch 22] | loss: 64.857 | test_loss: 51.151 |\n",
      "[Epoch 23] | loss: 64.714 | test_loss: 51.046 |\n",
      "[Epoch 24] | loss: 64.692 | test_loss: 50.716 |\n",
      "[Epoch 25] | loss: 64.516 | test_loss: 50.843 |\n",
      "[Epoch 26] | loss: 64.489 | test_loss: 50.559 |\n",
      "[Epoch 27] | loss: 64.487 | test_loss: 50.390 |\n",
      "[Epoch 28] | loss: 64.350 | test_loss: 49.914 |\n",
      "[Epoch 29] | loss: 64.134 | test_loss: 50.379 |\n",
      "[Epoch 30] | loss: 64.121 | test_loss: 49.895 |\n",
      "[Epoch 31] | loss: 64.137 | test_loss: 49.759 |\n",
      "[Epoch 32] | loss: 63.987 | test_loss: 49.801 |\n",
      "[Epoch 33] | loss: 63.854 | test_loss: 49.461 |\n",
      "[Epoch 34] | loss: 63.823 | test_loss: 49.803 |\n",
      "[Epoch 35] | loss: 63.790 | test_loss: 49.729 |\n",
      "[Epoch 36] | loss: 63.684 | test_loss: 49.231 |\n",
      "[Epoch 37] | loss: 63.712 | test_loss: 49.456 |\n",
      "[Epoch 38] | loss: 63.713 | test_loss: 49.414 |\n",
      "[Epoch 39] | loss: 63.748 | test_loss: 49.134 |\n",
      "[Epoch 40] | loss: 63.594 | test_loss: 49.088 |\n",
      "[Epoch 41] | loss: 63.580 | test_loss: 48.758 |\n",
      "[Epoch 42] | loss: 63.405 | test_loss: 49.023 |\n",
      "[Epoch 43] | loss: 63.391 | test_loss: 48.541 |\n",
      "[Epoch 44] | loss: 63.280 | test_loss: 48.790 |\n",
      "[Epoch 45] | loss: 63.166 | test_loss: 48.951 |\n",
      "[Epoch 46] | loss: 63.303 | test_loss: 48.584 |\n",
      "[Epoch 47] | loss: 63.250 | test_loss: 49.163 |\n",
      "[Epoch 48] | loss: 63.100 | test_loss: 48.576 |\n",
      "[Epoch 49] | loss: 63.294 | test_loss: 48.159 |\n",
      "[Epoch 50] | loss: 63.095 | test_loss: 48.140 |\n",
      "[Epoch 51] | loss: 63.131 | test_loss: 48.106 |\n",
      "[Epoch 52] | loss: 63.041 | test_loss: 48.352 |\n",
      "[Epoch 53] | loss: 62.854 | test_loss: 48.377 |\n",
      "[Epoch 54] | loss: 62.996 | test_loss: 48.090 |\n",
      "[Epoch 55] | loss: 62.986 | test_loss: 47.980 |\n",
      "[Epoch 56] | loss: 62.861 | test_loss: 48.058 |\n",
      "[Epoch 57] | loss: 63.105 | test_loss: 47.815 |\n",
      "[Epoch 58] | loss: 62.987 | test_loss: 48.141 |\n",
      "[Epoch 59] | loss: 62.889 | test_loss: 47.594 |\n",
      "[Epoch 60] | loss: 62.890 | test_loss: 47.949 |\n",
      "[Epoch 61] | loss: 62.856 | test_loss: 48.240 |\n",
      "[Epoch 62] | loss: 62.679 | test_loss: 47.880 |\n",
      "[Epoch 63] | loss: 62.665 | test_loss: 47.881 |\n",
      "[Epoch 64] | loss: 62.708 | test_loss: 47.736 |\n",
      "[Epoch 65] | loss: 62.794 | test_loss: 47.308 |\n",
      "[Epoch 66] | loss: 62.672 | test_loss: 47.657 |\n",
      "[Epoch 67] | loss: 62.617 | test_loss: 47.489 |\n",
      "[Epoch 68] | loss: 62.631 | test_loss: 47.504 |\n",
      "[Epoch 69] | loss: 62.500 | test_loss: 47.712 |\n",
      "[Epoch 70] | loss: 62.438 | test_loss: 48.023 |\n",
      "[Epoch 71] | loss: 62.546 | test_loss: 47.434 |\n",
      "[Epoch 72] | loss: 62.499 | test_loss: 47.092 |\n",
      "[Epoch 73] | loss: 62.520 | test_loss: 47.401 |\n",
      "[Epoch 74] | loss: 62.487 | test_loss: 46.952 |\n",
      "[Epoch 75] | loss: 62.359 | test_loss: 47.320 |\n",
      "[Epoch 76] | loss: 62.488 | test_loss: 47.434 |\n",
      "[Epoch 77] | loss: 62.501 | test_loss: 46.931 |\n",
      "[Epoch 78] | loss: 62.584 | test_loss: 47.160 |\n",
      "[Epoch 79] | loss: 62.364 | test_loss: 47.267 |\n",
      "[Epoch 80] | loss: 62.406 | test_loss: 47.195 |\n",
      "[Epoch 81] | loss: 62.447 | test_loss: 46.879 |\n",
      "[Epoch 82] | loss: 62.403 | test_loss: 46.750 |\n",
      "[Epoch 83] | loss: 62.320 | test_loss: 46.847 |\n",
      "[Epoch 84] | loss: 62.322 | test_loss: 46.923 |\n",
      "[Epoch 85] | loss: 62.354 | test_loss: 47.141 |\n",
      "[Epoch 86] | loss: 62.206 | test_loss: 46.821 |\n",
      "[Epoch 87] | loss: 62.182 | test_loss: 46.952 |\n",
      "[Epoch 88] | loss: 62.197 | test_loss: 46.759 |\n",
      "[Epoch 89] | loss: 62.149 | test_loss: 46.756 |\n",
      "[Epoch 90] | loss: 62.209 | test_loss: 47.104 |\n",
      "[Epoch 91] | loss: 62.133 | test_loss: 47.122 |\n",
      "[Epoch 92] | loss: 62.285 | test_loss: 46.745 |\n",
      "[Epoch 93] | loss: 62.185 | test_loss: 46.790 |\n",
      "[Epoch 94] | loss: 62.063 | test_loss: 46.944 |\n",
      "[Epoch 95] | loss: 62.156 | test_loss: 47.080 |\n",
      "[Epoch 96] | loss: 62.119 | test_loss: 46.697 |\n",
      "[Epoch 97] | loss: 62.105 | test_loss: 46.835 |\n",
      "[Epoch 98] | loss: 62.233 | test_loss: 46.911 |\n",
      "[Epoch 99] | loss: 62.016 | test_loss: 46.759 |\n",
      "[Epoch 100] | loss: 61.978 | test_loss: 46.821 |\n",
      "[Epoch 101] | loss: 61.932 | test_loss: 46.643 |\n",
      "[Epoch 102] | loss: 62.135 | test_loss: 46.681 |\n",
      "[Epoch 103] | loss: 61.878 | test_loss: 46.770 |\n",
      "[Epoch 104] | loss: 62.073 | test_loss: 46.442 |\n",
      "[Epoch 105] | loss: 61.990 | test_loss: 46.556 |\n",
      "[Epoch 106] | loss: 61.949 | test_loss: 46.616 |\n",
      "[Epoch 107] | loss: 61.914 | test_loss: 46.240 |\n",
      "[Epoch 108] | loss: 61.837 | test_loss: 46.389 |\n",
      "[Epoch 109] | loss: 61.853 | test_loss: 46.110 |\n",
      "[Epoch 110] | loss: 62.088 | test_loss: 46.491 |\n",
      "[Epoch 111] | loss: 61.972 | test_loss: 46.464 |\n",
      "[Epoch 112] | loss: 61.942 | test_loss: 46.138 |\n",
      "[Epoch 113] | loss: 61.929 | test_loss: 46.163 |\n",
      "[Epoch 114] | loss: 62.004 | test_loss: 46.562 |\n",
      "[Epoch 115] | loss: 62.021 | test_loss: 46.136 |\n",
      "[Epoch 116] | loss: 61.893 | test_loss: 46.180 |\n",
      "[Epoch 117] | loss: 61.935 | test_loss: 46.609 |\n",
      "[Epoch 118] | loss: 61.923 | test_loss: 46.128 |\n",
      "[Epoch 119] | loss: 61.801 | test_loss: 46.313 |\n",
      "[Epoch 120] | loss: 61.881 | test_loss: 46.174 |\n",
      "[Epoch 121] | loss: 61.867 | test_loss: 46.259 |\n",
      "[Epoch 122] | loss: 61.759 | test_loss: 46.379 |\n",
      "[Epoch 123] | loss: 61.738 | test_loss: 46.246 |\n",
      "[Epoch 124] | loss: 61.711 | test_loss: 46.376 |\n",
      "[Epoch 125] | loss: 61.790 | test_loss: 46.159 |\n",
      "[Epoch 126] | loss: 61.881 | test_loss: 46.114 |\n",
      "[Epoch 127] | loss: 61.762 | test_loss: 45.903 |\n",
      "[Epoch 128] | loss: 61.655 | test_loss: 45.993 |\n",
      "[Epoch 129] | loss: 61.823 | test_loss: 46.135 |\n",
      "[Epoch 130] | loss: 61.693 | test_loss: 46.283 |\n",
      "[Epoch 131] | loss: 61.738 | test_loss: 46.115 |\n",
      "[Epoch 132] | loss: 61.744 | test_loss: 46.133 |\n",
      "[Epoch 133] | loss: 61.621 | test_loss: 45.905 |\n",
      "[Epoch 134] | loss: 61.815 | test_loss: 46.219 |\n",
      "[Epoch 135] | loss: 61.581 | test_loss: 45.985 |\n",
      "[Epoch 136] | loss: 61.893 | test_loss: 45.886 |\n",
      "[Epoch 137] | loss: 61.908 | test_loss: 46.080 |\n",
      "[Epoch 138] | loss: 61.678 | test_loss: 46.578 |\n",
      "[Epoch 139] | loss: 61.638 | test_loss: 45.937 |\n",
      "[Epoch 140] | loss: 61.668 | test_loss: 46.001 |\n",
      "[Epoch 141] | loss: 61.654 | test_loss: 46.058 |\n",
      "[Epoch 142] | loss: 61.604 | test_loss: 45.932 |\n",
      "[Epoch 143] | loss: 61.621 | test_loss: 45.917 |\n",
      "[Epoch 144] | loss: 61.591 | test_loss: 45.920 |\n",
      "[Epoch 145] | loss: 61.711 | test_loss: 45.960 |\n",
      "[Epoch 146] | loss: 61.629 | test_loss: 45.940 |\n",
      "[Epoch 147] | loss: 61.518 | test_loss: 46.043 |\n",
      "[Epoch 148] | loss: 61.634 | test_loss: 45.934 |\n",
      "[Epoch 149] | loss: 61.510 | test_loss: 45.549 |\n",
      "[Epoch 150] | loss: 61.532 | test_loss: 45.928 |\n",
      "[Epoch 151] | loss: 61.661 | test_loss: 45.990 |\n",
      "[Epoch 152] | loss: 61.465 | test_loss: 45.815 |\n",
      "[Epoch 153] | loss: 61.735 | test_loss: 46.237 |\n",
      "[Epoch 154] | loss: 61.651 | test_loss: 45.672 |\n",
      "[Epoch 155] | loss: 61.532 | test_loss: 45.890 |\n",
      "[Epoch 156] | loss: 61.495 | test_loss: 45.975 |\n",
      "[Epoch 157] | loss: 61.457 | test_loss: 45.744 |\n",
      "[Epoch 158] | loss: 61.540 | test_loss: 45.558 |\n",
      "[Epoch 159] | loss: 61.524 | test_loss: 45.863 |\n",
      "[Epoch 160] | loss: 61.448 | test_loss: 45.841 |\n",
      "[Epoch 161] | loss: 61.496 | test_loss: 46.163 |\n",
      "[Epoch 162] | loss: 61.531 | test_loss: 45.611 |\n",
      "[Epoch 163] | loss: 61.438 | test_loss: 45.684 |\n",
      "[Epoch 164] | loss: 61.526 | test_loss: 45.987 |\n",
      "[Epoch 165] | loss: 61.488 | test_loss: 46.045 |\n",
      "[Epoch 166] | loss: 61.439 | test_loss: 45.719 |\n",
      "[Epoch 167] | loss: 61.643 | test_loss: 45.765 |\n",
      "[Epoch 168] | loss: 61.558 | test_loss: 45.404 |\n",
      "[Epoch 169] | loss: 61.382 | test_loss: 45.656 |\n",
      "[Epoch 170] | loss: 61.517 | test_loss: 45.351 |\n",
      "[Epoch 171] | loss: 61.426 | test_loss: 45.770 |\n",
      "[Epoch 172] | loss: 61.343 | test_loss: 45.861 |\n",
      "[Epoch 173] | loss: 61.433 | test_loss: 45.818 |\n",
      "[Epoch 174] | loss: 61.382 | test_loss: 45.448 |\n",
      "[Epoch 175] | loss: 61.336 | test_loss: 45.705 |\n",
      "[Epoch 176] | loss: 61.347 | test_loss: 45.554 |\n",
      "[Epoch 177] | loss: 61.391 | test_loss: 45.199 |\n",
      "[Epoch 178] | loss: 61.629 | test_loss: 45.541 |\n",
      "[Epoch 179] | loss: 61.422 | test_loss: 45.382 |\n",
      "[Epoch 180] | loss: 61.383 | test_loss: 45.698 |\n",
      "[Epoch 181] | loss: 61.486 | test_loss: 46.042 |\n",
      "[Epoch 182] | loss: 61.353 | test_loss: 45.685 |\n",
      "[Epoch 183] | loss: 61.496 | test_loss: 45.774 |\n",
      "[Epoch 184] | loss: 61.277 | test_loss: 45.570 |\n",
      "[Epoch 185] | loss: 61.408 | test_loss: 45.663 |\n",
      "[Epoch 186] | loss: 61.450 | test_loss: 45.520 |\n",
      "[Epoch 187] | loss: 61.330 | test_loss: 45.512 |\n",
      "[Epoch 188] | loss: 61.322 | test_loss: 45.555 |\n",
      "[Epoch 189] | loss: 61.294 | test_loss: 45.452 |\n",
      "[Epoch 190] | loss: 61.295 | test_loss: 45.326 |\n",
      "[Epoch 191] | loss: 61.285 | test_loss: 45.374 |\n",
      "[Epoch 192] | loss: 61.291 | test_loss: 45.607 |\n",
      "[Epoch 193] | loss: 61.431 | test_loss: 45.140 |\n",
      "[Epoch 194] | loss: 61.428 | test_loss: 45.216 |\n",
      "[Epoch 195] | loss: 61.276 | test_loss: 45.139 |\n",
      "[Epoch 196] | loss: 61.227 | test_loss: 45.212 |\n",
      "[Epoch 197] | loss: 61.390 | test_loss: 45.237 |\n",
      "[Epoch 198] | loss: 61.231 | test_loss: 45.082 |\n",
      "[Epoch 199] | loss: 61.309 | test_loss: 45.465 |\n",
      "[Epoch 200] | loss: 61.250 | test_loss: 45.152 |\n",
      "[Epoch 201] | loss: 61.273 | test_loss: 45.698 |\n",
      "[Epoch 202] | loss: 61.241 | test_loss: 45.242 |\n",
      "[Epoch 203] | loss: 61.311 | test_loss: 45.134 |\n",
      "[Epoch 204] | loss: 61.331 | test_loss: 45.791 |\n",
      "[Epoch 205] | loss: 61.278 | test_loss: 45.225 |\n",
      "[Epoch 206] | loss: 61.349 | test_loss: 45.615 |\n",
      "[Epoch 207] | loss: 61.184 | test_loss: 45.211 |\n",
      "[Epoch 208] | loss: 61.155 | test_loss: 45.471 |\n",
      "[Epoch 209] | loss: 61.226 | test_loss: 45.600 |\n",
      "[Epoch 210] | loss: 61.285 | test_loss: 45.231 |\n",
      "[Epoch 211] | loss: 61.237 | test_loss: 45.314 |\n",
      "[Epoch 212] | loss: 61.307 | test_loss: 45.352 |\n",
      "[Epoch 213] | loss: 61.326 | test_loss: 45.312 |\n",
      "[Epoch 214] | loss: 61.278 | test_loss: 45.155 |\n",
      "[Epoch 215] | loss: 61.153 | test_loss: 45.333 |\n",
      "[Epoch 216] | loss: 61.244 | test_loss: 45.345 |\n",
      "[Epoch 217] | loss: 61.260 | test_loss: 45.328 |\n",
      "[Epoch 218] | loss: 61.213 | test_loss: 44.981 |\n",
      "[Epoch 219] | loss: 61.316 | test_loss: 45.233 |\n",
      "[Epoch 220] | loss: 61.171 | test_loss: 44.964 |\n",
      "[Epoch 221] | loss: 61.121 | test_loss: 45.473 |\n",
      "[Epoch 222] | loss: 61.314 | test_loss: 45.402 |\n",
      "[Epoch 223] | loss: 61.306 | test_loss: 45.163 |\n",
      "[Epoch 224] | loss: 61.175 | test_loss: 45.534 |\n",
      "[Epoch 225] | loss: 61.026 | test_loss: 45.083 |\n",
      "[Epoch 226] | loss: 61.290 | test_loss: 44.963 |\n",
      "[Epoch 227] | loss: 61.140 | test_loss: 45.169 |\n",
      "[Epoch 228] | loss: 61.292 | test_loss: 45.146 |\n",
      "[Epoch 229] | loss: 61.155 | test_loss: 45.584 |\n",
      "[Epoch 230] | loss: 61.435 | test_loss: 45.226 |\n",
      "[Epoch 231] | loss: 61.184 | test_loss: 45.099 |\n",
      "[Epoch 232] | loss: 61.217 | test_loss: 45.442 |\n",
      "[Epoch 233] | loss: 61.247 | test_loss: 45.158 |\n",
      "[Epoch 234] | loss: 60.951 | test_loss: 45.123 |\n",
      "[Epoch 235] | loss: 61.306 | test_loss: 45.027 |\n",
      "[Epoch 236] | loss: 61.227 | test_loss: 45.193 |\n",
      "[Epoch 237] | loss: 61.094 | test_loss: 45.181 |\n",
      "[Epoch 238] | loss: 61.158 | test_loss: 45.049 |\n",
      "[Epoch 239] | loss: 61.222 | test_loss: 44.972 |\n",
      "[Epoch 240] | loss: 61.250 | test_loss: 45.409 |\n",
      "[Epoch 241] | loss: 61.194 | test_loss: 45.241 |\n",
      "[Epoch 242] | loss: 61.116 | test_loss: 44.755 |\n",
      "[Epoch 243] | loss: 61.180 | test_loss: 45.074 |\n",
      "[Epoch 244] | loss: 61.039 | test_loss: 45.177 |\n",
      "[Epoch 245] | loss: 61.134 | test_loss: 45.068 |\n",
      "[Epoch 246] | loss: 61.035 | test_loss: 45.333 |\n",
      "[Epoch 247] | loss: 61.125 | test_loss: 45.125 |\n",
      "[Epoch 248] | loss: 61.170 | test_loss: 44.987 |\n",
      "[Epoch 249] | loss: 61.066 | test_loss: 44.912 |\n",
      "[Epoch 250] | loss: 61.007 | test_loss: 45.136 |\n",
      "[Epoch 251] | loss: 60.984 | test_loss: 44.945 |\n",
      "[Epoch 252] | loss: 61.115 | test_loss: 45.432 |\n",
      "[Epoch 253] | loss: 60.915 | test_loss: 45.161 |\n",
      "[Epoch 254] | loss: 61.115 | test_loss: 45.224 |\n",
      "[Epoch 255] | loss: 61.020 | test_loss: 45.176 |\n",
      "[Epoch 256] | loss: 61.191 | test_loss: 45.044 |\n",
      "[Epoch 257] | loss: 61.102 | test_loss: 45.012 |\n",
      "[Epoch 258] | loss: 61.245 | test_loss: 44.746 |\n",
      "[Epoch 259] | loss: 61.062 | test_loss: 44.964 |\n",
      "[Epoch 260] | loss: 61.034 | test_loss: 44.806 |\n",
      "[Epoch 261] | loss: 61.143 | test_loss: 45.258 |\n",
      "[Epoch 262] | loss: 61.055 | test_loss: 45.283 |\n",
      "[Epoch 263] | loss: 60.992 | test_loss: 45.039 |\n",
      "[Epoch 264] | loss: 60.840 | test_loss: 45.359 |\n",
      "[Epoch 265] | loss: 61.070 | test_loss: 45.126 |\n",
      "[Epoch 266] | loss: 61.122 | test_loss: 44.997 |\n",
      "[Epoch 267] | loss: 61.047 | test_loss: 45.004 |\n",
      "[Epoch 268] | loss: 61.048 | test_loss: 44.866 |\n",
      "[Epoch 269] | loss: 61.003 | test_loss: 44.784 |\n",
      "[Epoch 270] | loss: 60.917 | test_loss: 45.071 |\n",
      "[Epoch 271] | loss: 61.004 | test_loss: 44.440 |\n",
      "[Epoch 272] | loss: 61.004 | test_loss: 45.115 |\n",
      "[Epoch 273] | loss: 61.071 | test_loss: 45.025 |\n",
      "[Epoch 274] | loss: 61.067 | test_loss: 44.879 |\n",
      "[Epoch 275] | loss: 60.834 | test_loss: 44.879 |\n",
      "[Epoch 276] | loss: 60.966 | test_loss: 44.867 |\n",
      "[Epoch 277] | loss: 61.116 | test_loss: 44.673 |\n",
      "[Epoch 278] | loss: 61.008 | test_loss: 44.979 |\n",
      "[Epoch 279] | loss: 61.013 | test_loss: 44.807 |\n",
      "[Epoch 280] | loss: 60.984 | test_loss: 44.936 |\n",
      "[Epoch 281] | loss: 61.107 | test_loss: 45.042 |\n",
      "[Epoch 282] | loss: 60.972 | test_loss: 44.886 |\n",
      "[Epoch 283] | loss: 60.995 | test_loss: 45.140 |\n",
      "[Epoch 284] | loss: 60.953 | test_loss: 45.160 |\n",
      "[Epoch 285] | loss: 61.099 | test_loss: 44.921 |\n",
      "[Epoch 286] | loss: 60.931 | test_loss: 44.989 |\n",
      "[Epoch 287] | loss: 60.958 | test_loss: 45.049 |\n",
      "[Epoch 288] | loss: 60.978 | test_loss: 45.207 |\n",
      "[Epoch 289] | loss: 61.027 | test_loss: 44.798 |\n",
      "[Epoch 290] | loss: 60.961 | test_loss: 44.825 |\n",
      "[Epoch 291] | loss: 61.005 | test_loss: 44.867 |\n",
      "[Epoch 292] | loss: 60.895 | test_loss: 44.923 |\n",
      "[Epoch 293] | loss: 61.183 | test_loss: 44.786 |\n",
      "[Epoch 294] | loss: 60.828 | test_loss: 44.933 |\n",
      "[Epoch 295] | loss: 60.896 | test_loss: 44.882 |\n",
      "[Epoch 296] | loss: 60.925 | test_loss: 44.599 |\n",
      "[Epoch 296] Early stopping\n",
      "Saving model to ... trained_vae.pt\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(random_seed)\n",
    "#Preprocessing \n",
    "prep_data = VAE_prepare_dataset(adata, column_labels_name, random_seed, name_model, train_size, pathway_file, preprocess, select_hvg, n_top_genes) \n",
    "adata = prep_data.preprocess_data(adata, name_model, preprocess, select_hvg, n_top_genes)\n",
    "X, y = prep_data.extract_x_y_from_adata(adata, column_labels_name)\n",
    "X_train,  X_test, labels_train,  labels_test = prep_data.split_data(X, y, train_size, random_seed)\n",
    "y_train = prep_data.encode_y(labels_train)\n",
    "y_test = prep_data.encode_y(labels_test)\n",
    "index_train = prep_data.extract_index(X_train)\n",
    "index_test = prep_data.extract_index(X_test)\n",
    "adata_train, index_train = prep_data.build_adata_from_X(adata, index_train)\n",
    "adata_test, index_test = prep_data.build_adata_from_X(adata, index_test)\n",
    "\n",
    "if exist_val_set == True:\n",
    "    X_train,  X_val, labels_train,  labels_val = prep_data.split_data(X_train, labels_train, train_size, random_seed)\n",
    "    y_val = prep_data.encode_y(labels_val)\n",
    "    index_val = prep_data.extract_index(X_val)\n",
    "    adata_val, index_val = prep_data.build_adata_from_X(adata, index_val)\n",
    "\n",
    "train_data, pathway_dict_train, pathway_mask_train = prep_data. build_vega_dataset(adata_train, y_train, pathway_file)\n",
    "val_data, pathway_dict_val, pathway_mask_val = prep_data. build_vega_dataset(adata_val, y_val, pathway_file)\n",
    "test_data, pathway_dict_test, pathway_mask_test = prep_data.build_vega_dataset(adata_test, y_test, pathway_file)\n",
    "\n",
    "n = f'{perturbation}_seed_{random_seed}'\n",
    "\n",
    "beta = 0.00005\n",
    "dropout = 0.5\n",
    "batch_size =64\n",
    "lr = 1e-4\n",
    "n_epochs = 800\n",
    "train_p=25\n",
    "test_p=25\n",
    "pos_dec = True\n",
    "save_path = save_model_path + f'trained_VEGA_{n}'\n",
    "\n",
    "model_training = Vega_train_multiple_times(adata_train, adata_val, adata_test, name_model, name_dataset, n, train_data, val_data, test_data, n_epochs, lr, pathway_mask_train, batch_size, beta, dropout, train_p, test_p, pos_dec, dev, save_path, path_to_save_embeddings, path_to_save_reconstructed)\n",
    "train_loader, val_loader, test_loader = model_training.build_data_loader(train_data, val_data, test_data, batch_size, name_model)\n",
    "hist = model_training.train_VEGA(adata_train, adata_val, adata_test, train_loader, val_loader, n, n_epochs, lr, pathway_mask_train, dev, beta, save_path, dropout, pos_dec, train_p, test_p, path_to_save_embeddings, path_to_save_reconstructed, name_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489fdaaa-d3cd-4213-b61b-63525f677d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "new_env_vega_1",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "new_env_VEGA_1",
   "language": "python",
   "name": "new_env_vega_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
